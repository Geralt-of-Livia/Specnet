{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic spectra generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 15\n",
    "n_points = 640\n",
    "nu = np.linspace(0,1,n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chi3():\n",
    "    \"\"\"\n",
    "    generates a random spectrum, without NRB. \n",
    "    output:\n",
    "        params =  matrix of parameters. each row corresponds to the [amplitude, resonance, linewidth] of each generated feature (n_lor,3)\n",
    "    \"\"\"\n",
    "    n_lor = np.random.randint(1,max_features)\n",
    "    a = np.random.uniform(0,1,n_lor)\n",
    "    w = np.random.uniform(0,1,n_lor)\n",
    "    g = np.random.uniform(0.001,0.008, n_lor)\n",
    "    \n",
    "    params = np.c_[a,w,g]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chi3(params):\n",
    "    \"\"\"\n",
    "    buiilds the normalized chi3 complex vector\n",
    "    inputs: \n",
    "        params: (n_lor, 3)\n",
    "    outputs\n",
    "        chi3: complex, (n_points, )\n",
    "    \"\"\"\n",
    "    \n",
    "    chi3 = np.sum(params[:,0]/(-nu[:,np.newaxis]+params[:,1]-1j*params[:,2]),axis = 1)\n",
    "    \n",
    "    return chi3/np.max(np.abs(chi3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,c,b):\n",
    "\treturn 1/(1+np.exp(-(x-c)*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nrb():\n",
    "    \"\"\"\n",
    "    Produces a normalized shape for the NRB\n",
    "    outputs\n",
    "        NRB: (n_points,)\n",
    "    \"\"\"\n",
    "    bs = np.random.normal(10,5,2)\n",
    "    c1 = np.random.normal(0.2,0.3)\n",
    "    c2 = np.random.normal(0.7,.3)\n",
    "    cs = np.r_[c1,c2]\n",
    "    sig1 = sigmoid(nu, cs[0], bs[0])\n",
    "    sig2 = sigmoid(nu, cs[1], -bs[1])\n",
    "    nrb  = sig1*sig2\n",
    "    return nrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum():\n",
    "    \"\"\"\n",
    "    Produces a cars spectrum.\n",
    "    It outputs the normalized cars and the corresponding imaginary part.\n",
    "    Outputs\n",
    "        cars: (n_points,)\n",
    "        chi3.imag: (n_points,)\n",
    "    \"\"\"\n",
    "    chi3 = build_chi3(random_chi3())*np.random.uniform(0.3,1)\n",
    "    nrb = generate_nrb()\n",
    "    noise = np.random.randn(n_points)*np.random.uniform(0.0005,0.003)\n",
    "    cars = ((np.abs(chi3+nrb)**2)/2+noise)\n",
    "    return cars, chi3.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras import regularizers\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None,input_shape = (n_points, 1)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(128, activation = 'relu', kernel_size = (32)))\n",
    "model.add(Conv1D(64, activation = 'relu', kernel_size = (16)))\n",
    "model.add(Conv1D(16, activation = 'relu', kernel_size = (8)))\n",
    "model.add(Conv1D(16, activation = 'relu', kernel_size = (8)))\n",
    "model.add(Conv1D(16, activation = 'relu', kernel_size = (8)))\n",
    "model.add(Dense(32, activation = 'relu', kernel_regularizer=regularizers.l1_l2(l1 = 0, l2=0.1)))\n",
    "model.add(Dense(16, activation = 'relu', kernel_regularizer=regularizers.l1_l2(l1 = 0, l2=0.1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(n_points, activation='relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='Adam', metrics=['mean_absolute_error','mse','accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(size = 10000):\n",
    "    X = np.empty((size, n_points,1))\n",
    "    y = np.empty((size,n_points))\n",
    "    \n",
    "    for i in range(size):\n",
    "        X[i,:,0], y[i,:] = get_spectrum()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_batch(50000)\n",
    "history = model.fit(X, y,epochs=10, verbose = 1, validation_split=0.25, batch_size=256) \n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to test the model on single instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot():\n",
    "    x,y = generate_batch(1)\n",
    "    yhat = model.predict(x, verbose =0)\n",
    "    f, a = plt.subplots(2,1, sharex=True)\n",
    "    a[0].plot(x.flatten(), label = 'cars')\n",
    "    a[1].plot(y.T+.7, label = 'true',c= 'g' )\n",
    "    a[1].plot(yhat.flatten()+1.4, label = 'pred.',c='r')\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    #return x, y.flatten(), yhat.flatten(), chi3, NRB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
